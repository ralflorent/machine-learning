{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Machine Learning - Mini Project II\n",
    "\n",
    "### Learning Algorithm: Classifier\n",
    "\n",
    "Created on March 10, 2019 by Diogo Cosin <d.ayresdeoliveira@jacobs-university.de> and Ralph Florent <r.florent@jacobs-university.de>.\n",
    "\n",
    "### Description\n",
    "Train a classifier for the Digits dataset by implementing a full processing pipeline from feature extraction to (linear) classifier training, attempting to squeeze performance out of the classifier using cross-validation and regularization techniques.\n",
    "\n",
    "### Summary\n",
    "The script below is intended to... \n",
    "\n",
    "WIP\n",
    "\n",
    "Note: The algorithm is tested on the OCR datasets from the `DigitsBasicsRoutine.zip`, which was provided by Professor Dr. H. Jaeger, Machine Learning Professor at [Jacobs University Bremen](https://www.jacobs-university.de)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Learning Algorithm: Classifier \"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "# \n",
    "# Created on April 01, 2019\n",
    "# Authors: \n",
    "#        Diogo Cosin <d.ayresdeoliveira@jacobs-university.de>,\n",
    "#        Ralph Florent <r.florent@jacobs-university.de>\n",
    "\n",
    "\n",
    "# Import relevant libraries\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('./assets/')\n",
    "from miniprojectone import get_data_points, k_means, get_codebooks\n",
    "\n",
    "\n",
    "# START: Helper functions\n",
    "def load_data(one_hot_encoding=None):\n",
    "    \"\"\" Load the data and parse (if specified, one-hot encoding) numbered \n",
    "        class labels.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        one_hot_encoding: bool, None\n",
    "            determine whether one-hot encoding should be used or not\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        dataframe: array-like (n_samples, m_features)\n",
    "    \"\"\"\n",
    "    # load data frame with no class labels defined\n",
    "    dataframe = get_data_points()\n",
    "    if one_hot_encoding is None:\n",
    "        return dataframe\n",
    "    return inject_label(dataframe, one_hot_encoding)\n",
    "\n",
    "def one_hot_encode(ith, k=10):\n",
    "    \"\"\" Apply one-hot encoding technique for a k-dimensional vector\n",
    "        \n",
    "        This function is intended to work like a lightweight version one-hot-encoder.\n",
    "        It is adapted to our specific needs. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        ith: int\n",
    "            ith position of the one-of-K discrete label\n",
    "        \n",
    "        k: int\n",
    "            number of k-classes for the encoding vector\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        encoded: array\n",
    "            vector with zeros and one in the ith position\n",
    "    \"\"\"\n",
    "    if ith > k:\n",
    "        ith = k # avoid out of bound exception\n",
    "        \n",
    "    index = ith - 1\n",
    "    encoded = np.zeros(k)\n",
    "    encoded[index] = 1\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def inject_label(dataset, one_hot_encoding=False):\n",
    "    \"\"\" Inject into data frame class labels as numbered or one-hot encoded \n",
    "    \"\"\"\n",
    "    dataframe, k_class = [], 10\n",
    "    digits = np.array_split(dataset, k_class) # split into 10 arrays\n",
    "    for i in range(k_class):\n",
    "        digit =  digits[i] # n-obs x k-dim\n",
    "        if i == 0: \n",
    "            i = 10 # define \"0\" as class 10\n",
    "        encoded = one_hot_encode(i) if one_hot_encoding else i\n",
    "        \n",
    "        for point in digit:\n",
    "            dataframe.append( np.insert(point, len(point), encoded) )\n",
    "            \n",
    "    return np.array(dataframe) \n",
    "\n",
    "\n",
    "def split_data(dataframe):\n",
    "    \"\"\" Split data frame into training and testing data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: array-like (n_samples, m_features)\n",
    "        2000 digit patterns x 240 features and 10 one-hot encoded class labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    encoded: list\n",
    "        list containing array of training and array of testing data\n",
    "    \"\"\"\n",
    "    digits = np.array_split(dataframe, 10)\n",
    "    \n",
    "    train_data, test_data = [], []\n",
    "\n",
    "    for digit in digits:\n",
    "        train_data.extend(digit[:100])\n",
    "        test_data.extend(digit[100:])\n",
    "    \n",
    "    return [np.array(train_data), np.array(test_data)]\n",
    "\n",
    "\n",
    "def select_features(dataset, K=1):\n",
    "    \"\"\" Apply Euclidean distance between k-means centroid and each point\n",
    "    to extract k features.\n",
    "    \"\"\"\n",
    "    clusters = k_means(dataset, K)\n",
    "    codebooks = get_codebooks(clusters)\n",
    "    features = []\n",
    "    # transfrom xi -> fi by reducing dimensionality from n to k features\n",
    "    for point in dataset:\n",
    "        # compute distance between data point and centroid \n",
    "        feature = [np.linalg.norm(point - c) for c in codebooks]\n",
    "        features.append( np.array(feature) )\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "def linear_regressor(alpha=0):\n",
    "    weights = []\n",
    "    return weights\n",
    "\n",
    "# END: Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading training and testing data\n",
    "The `load_data` function helps framing the data with numbered or one-hot encoding class labels to build an in-memory data frame. \n",
    "\n",
    "Given this data frame, let's load the first 100 digit-patterns as training data and the second 100 as testing data, for a specific digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 250) (1000, 250) (1000, 250)\n"
     ]
    }
   ],
   "source": [
    "dataframe = load_data(one_hot_encoding=True)\n",
    "\n",
    "# Distribute dataframe into training and testing data\n",
    "training_data, testing_data = split_data(dataframe)\n",
    "\n",
    "print(dataframe.shape, training_data.shape, testing_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "Let's use K-means clustering algorithm to select relevant features in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 240) (1000, 19)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "raw_dataframe = load_data()\n",
    "raw_training_data, raw_testing_data = split_data(raw_dataframe)\n",
    "\n",
    "selected_features = select_features(raw_training_data, 20)\n",
    "print(raw_dataframe.shape, selected_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 29)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_labels = inject_label(selected_features, one_hot_encoding=True)\n",
    "features_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier: Linear Regression\n",
    "\n",
    "Let's compute the linear regression weights with a trailing 1 as bias\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
